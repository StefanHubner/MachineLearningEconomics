Stability and Statistics
Speech given by
Rachel Lomax, Deputy Governor of the Bank of England

The North Wales Business Club Dinner, Llandudno, Wales
23 November 2004

I would like to thank Simon Hayes and Jens Larsen for research support and Spencer Dale, Mark
Cornelius and colleagues at the Bank of England for helpful comments.
1

All speeches are available online at www.bankofengland.co.uk/publications/Pages/speeches/default.aspx

2
‘The first time we saw the MPC we were given the folder of all the
statistics they had which was something like a foot high. We found it
hard to believe that they all read that stuff but they claimed they did.
Statistics seem to be their life blood…’
Chairman, House of Lords, Select Committee on Economic Affairs,
HL Paper 176 - II
The past decade has been a time of unparalleled stability for the UK economy.
It is more than twelve years since the United Kingdom experienced a single quarter of
negative GDP growth. Consumer spending, investment and output have all shown a
degree of stability over the past ten years which is unmatched in any decade since the
war – indeed in the twentieth century. Inflation has been impressively stable too, as
well as lower on average than at any time since the war. And, to complete the story,
employment has grown steadily, and unemployment has fallen to a 30 year low.
A stable economy has created a much better climate for business. So no wonder
soaring oil prices make people nervous. Those with long memories know we have
achieved low inflation and steady growth before – though never for so long – only
to see them slip away. They ask: what’s to prevent that happening again?
A lot has changed in the past fifteen years. We now have an approach to setting
interest rates which provides much better incentives for policy makers to take the
right decisions. This – and the strong track record built up over the past decade –
has stabilised expectations, with the result that it takes more to throw inflation off
course. This is crucial insurance against the risks of a more turbulent decade ahead.
A trickier issue – and one on which I want to spend some time tonight – is the vexed
question of information. Statisticians get an even worse press than economists. But
they are indispensable. Just as well run businesses need good management
information, so successful monetary policy depends on having good information
about the economy. The statistical fog surrounding the true state of the economy has
proved a particularly potent breeding ground for policy errors in the past. Are we
yet in sight of a clearer view?
The policy framework
But let me start first with the policy framework: what grounds are there for being
confident that it provides the right incentives for policy makers to take good
decisions?

3
The origins of the present approach go back to 1992, when the Conservative
government adopted an inflation target as the centrepiece of a package of reforms
designed to rebuild credibility with financial markets in the wake of sterling’s abrupt
departure from the ERM. This approach – which came to include the popular ‘Ken
and Eddie show’ – proved successful in establishing a track record of low and stable
inflation. In 1997, the incoming Labour Government ‘entrenched’ this success by
handing the operation of monetary policy over to the Bank of England and setting out
a detailed institutional and legal framework for the conduct of monetary policy. The
result was to depoliticise interest rate decisions, within a framework of accountability
that left the Government clearly in charge of setting objectives for inflation.
Taking operational monetary policy decisions out of the hands of politicians was a
decisive step. The touchstone of a successful monetary policy framework is its
credibility. If people believe policy makers will always act to keep inflation low, this
expectation will itself put a brake on inflationary wage and price increases.
Economists long argued that it was difficult for politicians to make a fully credible
commitment to low inflation. And perceptions are what matter: even if a government
has no intention of manipulating monetary policy for political ends, as long as firms,
workers and financial markets entertain that as a possibility, the job of keeping
inflation low will be that much harder.
Nowadays, the Chancellor specifies the inflation target each year, in a letter to the
Governor, but decisions about interest rates are taken by a Committee of nine
independent experts who have strong incentives to keep inflation close to target.
That is not just because a measurable target provides a clear focus for decisions,
important as that is. The regime is intentionally highly transparent with a heavy
emphasis on accountability to Parliament and the general public as well as the
government of the day. Our individual votes are a matter of public record, and we
regularly appear in front of the Treasury Committee to explain our decisions. Minutes
of MPC meetings are published within a fortnight. And every three months, we
publish an Inflation Report, with the MPC s views on the outlook for growth and
inflation over the next three years. This is the subject of regular briefings to business
audiences around the country as well as a high profile press conference fronted by the
Governor.

4
All this gives monetary policy watchers – in financial markets and in the country at
large – plenty of information by which to judge how we are doing, as well as to form
their own expectations of future inflation and growth.
How successful have we been in establishing a credible policy regime? A key test is
what people expect about inflation, and in particular how those expectations react to
unexpected economic news. If the regime is credible, people should expect inflation
to stay close to target. And any shocks that affect inflation in the near-term should
have no impact on inflation expectations further out, because people believe we will
take whatever action is needed to return inflation to target. And by this measure, the
current policy framework seems to be highly credible.
There are those who claim that the MPC has never really been tested. In fact, the UK
economy has been hit by a number of quite severe shocks over the past five or six
years. International financial markets were convulsed by the Asian financial crisis in
1997, the Russian debt default and LTCM crisis in 1998, the 9/11 terrorist attacks, the
Enron and WorldCom scandals in 2001/2 which dented confidence in corporate
governance. Around the same time, we also saw the bursting of the dot.com bubble
and a slowdown in world activity.
In the past decades, shocks like this would almost certainly have destabilised UK
economic activity and inflation. That, after all, is what happened in the 1970s, when
the price of oil quadrupled, and then again in 1979 when it more than doubled. Since
the late 90s however, medium-term inflation expectations – both as measured by
surveys and as implied by financial asset prices – have barely budged. Even this year,
when oil prices rose by over 70% to their peak in late October before falling back, and
other producer input prices, including metals, have surged ahead, both surveys and
financial asset prices show inflation expectations fluctuating around the MPCs
inflation target, within a very narrow range.
This remarkable de-coupling of inflation expectations from economic disturbances is
the single most encouraging indicator that the new monetary policy framework is
doing its bit to ensure continued economic stability.
The importance of reliable information
In monetary policy as in business, reputations that have taken decades to build can be
lost with distressing speed: it only takes one banana skin to turn a confident stroll into

5
a painful tumble. And while monetary policy may be a matter for experts these days,
it is very far from being a precise science.
Any honest assessment of the economic outlook comes with very large health
warnings. That’s why, in its quarterly Inflation Reports the MPC discusses at some
length the main economic risks that may knock its central projection off course. These
tend focus on events beyond our control – the state of the world economy for example
– or gaps in our understanding of key economic relationships – such as the link
between house prices and household spending. The minutes of our policy meetings
reflect a lively awareness of the range of possible outcomes which need to be factored
into decisions taking.
But few subjects consume more of our time and energy than another, more insidious,
source of uncertainty: one with which the MPC does daily battle – the data. As the
last Governor liked to remark, ‘There are three kinds of economists – those who can
count and those who can’t’. The MPC is emphatically in the first group; we agree
with Sherlock Holmes, ‘It is a capital mistake to theorise before one has data’.
Indeed, as Lord Peston, Chairman of the House of Lords Select Committee on
Economic Affairs, recently observed, referring to our foot high data pack: ‘Statistics
seem to be [the MPCs] life blood’.
Why should this be so?
The MPC sets interest rates in response to its assessment of the outlook for economic
activity: the key question is whether the level of aggregate demand is above or below
the economy’s capacity to supply. The difficulty – and it is a fundamental one – is
that we cannot observe the true values of many key macroeconomic variables, such as
aggregate demand.
Of course, the Office for National Statistics (ONS) produces estimates of such
variables. These are derived from comprehensive surveys of firms and households,
and provide the most authoritative available guide to macroeconomic developments.
But measuring economic activity across the whole of the UK is a hugely complex and
difficult task, and 100% accuracy is simply not feasible.
And producing reliable estimates takes time. If the ONS waited two or three years
before publishing their first estimates, they would have reasonably complete
information. But it would be of rather limited value for policy purposes. We need

6
more timely indicators of economic activity, even though these will tend to be less
accurate than later estimates.
That is why the ONS publishes preliminary estimates of key data a few weeks after
the month or quarter to which they refer, derived from sub-sets of their overall
samples. As time passes, more information is processed and estimates are revised,
making them progressively more accurate.
But the fact remains that the data that give the timeliest read on economic activity are
also the ones that are measured least accurately. So there is always a risk that the
official data will give a misleading view of the current economic situation.
Reading the economy is difficult
And indeed there have been times when economic policy has been led astray by
misleading data. For example, in the second half of the 1980s economic policy was
founded on the view – indicated by the official data at the time – that the pace of
recovery from recession had been relatively modest, and there was considerable spare
capacity in the economy.
But a sequence of data revisions proved that view to be wrong. Nigel Lawson, who
was Chancellor at the time, recalled that revisions to the trade figures in 1988 made it
clear to him that ‘demand in the economy was pressing against the limits of capacity
to a much greater degree than I had previously realised’. The GDP figures were also
heavily revised. For example, growth in 1986 was initially estimated at 2.4% (in
early 1987) – close to economists’ view of trend growth. Three years later – in 1990
– this had been revised up to 3.6%. The latest (2004) estimate is that growth was
actually 4% – a long way above trend.
As Robin Leigh-Pemberton, then Governor of the Bank of England, said
‘we put the brakes on when the speedometer indicated we were doing
60mph. Some time later it was revealed we were doing 55. When the
tachograph was opened, however, it revealed that we had actually been
doing 70, when the speedometer read 60… more brake pressure was
therefore entirely appropriate.’
This episode marked a low point for the UK’s GDP statistics in recent times. Since
then, a number of methodological changes have been introduced, and data sources
have been improved. Analysis both by the ONS and the Statistics Commission

7
indicates a dramatic reduction in the average size of revisions over the past fifteen
years. Even so, measuring the economy remains a complex task, and data uncertainty
is a fact of life.
So what does the MPC do to ensure its judgements are as firmly grounded in reality as
possible?
We have a four pronged approach:
•

We monitor a very wide range of data

•

We pay careful attention to data quality

•

We talk to business people around the country

•

We are working closely with ONS to transform the quality of official
statistics

Monitoring a wide array of indicators
First, we critically review an enormous quantity of data. The MPC regularly monitors
more than 1,500 data series, of which around 1,000 are for the UK. The point of
doing this is that often there are puzzles and questions about the behaviour of the
economy to which no single piece of data can provide a complete answer. But we
may build up a convincing picture by piecing together a range of indicators.
The housing market provides a classic example of this approach. There is an
enormous array of indicators of housing market activity – data on mortgage approvals
and lending, house price indices from the main lenders (the Halifax and the
Nationwide), the Office of the Deputy Prime Minister and the Land Registry, and
various surveys of estate agents and house builders. One approach would be to pick
out a single indicator, and monitor that. But experience shows that none of these
indicators individually has consistently given a plausible indication of developments
in the housing market; the indicators provide a better guide when taken together. So
we monitor a full set of housing market indicators, and we have found that the clearest
signals come when all of the indicators are pointing in the same direction. In
economic assessment, there is safety in numbers.

8
Awareness of data quality
But looking at a large array of indicators can be bewildering without some way of
narrowing the focus. So the second element of our approach is to recognise explicitly
that data vary widely in their quality, and hence in their usefulness for policy
assessment. Bank staff grade data series on a number of quality criteria, and we use
this grading to make the best use of the available information.
The basic principle is simple: a sensible approach to economic assessment takes a
weighted average of all available indicators, where the weight placed on each reflects
the quality of that indicator relative to other available data. Generally speaking, in
terms of overall accuracy the highest quality data come from the ONS and other
national statistical agencies. This is scarcely surprising, since they have a very
comprehensive information base. For example, ONS data on manufacturing output
are based on surveys of 10,000 of the UK’s 160,000 manufacturers. All firms with
more than 150 employees are surveyed, supplemented by stratified random sampling
of smaller companies.
Some private-sector business organisations – such as the Chartered Institute of
Purchasing and Supply, the CBI and the British Chambers of Commerce – also
publish surveys of manufacturers. But these samples are typically less than one-tenth
of the size of those used by the ONS.
On top of that, the private-sector surveys ask only whether activity has risen or fallen,
rather than recording exactly how much activity has changed. This can be a particular
problem when sub-sectors of an industry are experiencing dramatic movements in
output compared with the rest of the sector. For example, manufacturing output
declined quite sharply between 1999 and 2002, driven by sharp falls in ICT output, as
the strong growth in business spending on IT through the mid 1990s came to an
abrupt halt. But the dip in the manufacturing survey balances in this period was much
less pronounced than the ONS’s estimated fall in output. This was due in part to the
qualitative nature of the surveys, which meant that ICT firms could record only that
their output had fallen - and not that it had fallen off a cliff!
In principle then, the ONS data should provide the most accurate guide to
developments in UK economic activity. But monetary policy decisions are made
every month, and need to be informed by the best assessment of economic activity
available at that time. That is why the MPC sets particular store on timely economic
data – that is, data that are released soon after the period to which they refer.

9
This is where the business surveys really can add value. For example, the CIPS
surveys for the manufacturing and services sectors are released just a few days after
the reference month. This is around one month before ONS manufacturing output
estimates are available, and around two months before the ONS releases its monthly
service sector data. The private sector surveys may be less accurate than the ONS
data; but so long as we bear that additional uncertainty in mind, they can be a valuable
addition to the MPC’s armoury.
In fact, recent work by Bank staff has shown that, even when preliminary ONS
estimates are available, combining these with the information from the business
surveys can provide a more accurate assessment than if we were to throw the business
survey information away and rely solely on the ONS data.
This type of analysis is influencing our judgement at the moment. The ONS’s
preliminary estimate of GDP growth in the third quarter was just 0.4%, suggesting a
marked slowdown in growth driven by a sharp contraction in industrial output. But
business surveys suggest that manufacturing output continues to expand. Taking
these two pieces of information together, the MPC judges that overall growth was a
little higher in Q3 than the official data currently indicate.
We talk to people
A third way of reducing the risk of error is to talk to people on the ground. If the
hard data are at odds with what they are telling us, that will give us pause for thought
– about the likely economic outlook, or at least the risks around our central view.
Back in the early 90s a familiar charge against the Treasury (which at that time had
primary responsibility for setting interest rates) was that they were out of touch –
stuck in London, they missed early signs of the recession. The Bank has been careful
to avoid this trap. It has built up a network of agencies to act as its eyes and ears
around the country.
That regional network has grown out of the Bank's branches that were established in
1826 to deal with problems caused by the failure of local banknote-issuing banks.
(The nearest branch to North Wales would have been in Liverpool, and like several
of the sixteen branches which the Bank opened at that time it was located on land
previously occupied by licensed premises – the old Queen’s Arms in Castle Street.
Indeed the guiding principle seems to have been ‘If it works as a pub it will work as a

10
bank’. The Licensed Victuallers Association has taken its revenge in recent decades,
as old banks have been turned into pubs).
Within the branches, the Bank appointed an Agent to liaise with local industry and
commerce, and since 1930 they have been sending regular reports on their economies
to Threadneedle Street. During the 1980s and 1990s, most of the branches were
closed as different schemes for guaranteeing the supply of bank notes were
established. But the Agents remained, and the network was extended to its current
line-up of twelve – including a new Welsh Agency located in Cardiff, now run by
Adrian Piper.
Between them, the Agents are in regular contact with some 8000 firms. This
provides the basis for the Agents’ monthly reports and presentations to the MPC; the
Committee also commissions special surveys and asks for Agents’ help in
understanding puzzles in the data. This information is currently published in
summary form each quarter, alongside the Inflation Report. We are now looking at
ways of making it available on a monthly basis, alongside the minutes of the MPC
meeting.
MPC members regularly take their own eyes and ears on visits to individual
businesses, making around 60 visits to the regions a year. As well as acting as a
reality check on economic statistics, talking to businesses around the country
improves our understanding of longer-term changes in economic environment. These
visits are a good opportunity to discuss issues as varied as the impact of migrant
labour on skill shortages; or outsourcing to China; or the growth of buy to let
housing; or the changing structure of the retailing sector; or even the impact of
weather and public holidays on the pattern of consumer spending.
And in unusual economic circumstances, the Agents’ network of contacts can give us
information that is not available from any other source. The outbreak of Foot and
Mouth Disease in 2001 is a case in point. Our Agents helped us to identify in real
time the wider effects on the non agricultural sectors of the economy, notably of
course tourism – and that gave us a better picture of the underlying development of
the economy.
We support measures to improve the quality of official statistics
Finally, and most important, our longer-term strategy for mitigating data uncertainty
is to support the ONS in improving the quality of the national statistics. Bank staff

11
maintain very close links with their ONS counterparts both on a day-to-day basis, and
in developing their ambitious modernisation programme.
This was already in hand when the Chancellor of the Exchequer commissioned Chris
Allsopp, a former member of the MPC, to assess how well the ONS’s provision of
statistics matched the needs of policymakers. The Allsopp Report, published earlier
this year, has recommended some fundamental changes to the way that key economic
data are put together. These concern regional and service sector data; and the ONS’s
capacity to respond to changes in the structure of the economy.
First, Allsopp recommends that the national statistical system should be reoriented to
produce better quality regional data. This is likely to involve, for example,
establishing an ONS office in every English region – not dissimilar to the Bank’s
Agency network. The ONS’s main business surveys are also to be expanded to obtain
greater regional coverage. For example, the Annual Business Inquiry – a major
workhorse of economic statistics, which provides detailed information on, for
example, employment, production and investment – is likely to be trebled in size.
Monetary policy operates at the level of the whole economy, and cannot target
particular regions or countries of the UK. But to the extent that better measurement
and understanding of regional activity leads to improvements in the quality of UK
national statistics, as the Allsopp Report expects, this development will improve the
information base on which monetary policy is founded.
The second main focus of the Allsopp review is the stark imbalance between the
coverage, timeliness and quality of statistics on the services sector relative to those on
manufacturing. Suppose you were interested in studying the economic behaviour of
the UK textiles industry – which accounts for around one-third of one percent of UK
output. The good news is there’s plenty of coverage in the national accounts,
although you have some decisions to make. Are you interested in clothing, or carpets
and rugs? And if clothing, are you interested in knitted and crocheted garments…or
work wear…or outerwear?…or indeed underwear? Each of these has its own data
set: the array of sub-categories is truly impressive.
However, suppose instead that you were interested in the retail sector, and wanted to
know, for example, how much the large supermarket chains have contributed to GDP
in recent years, or what inroads they have made into the non-food market. No dice.
Although the retail sector nowadays accounts for over 5% of UK output – so it is

12
nearly 20 times the size of the textiles industry – more detailed data are not produced
for the UK national accounts.
The need for better service sector statistics goes well beyond any interest we might
have in detail for its own sake. In the UK, early estimates of GDP rely heavily on
measuring output. Since the service sector accounts for more than 70% of UK output,
the quality of early GDP estimates is inextricably linked to the quality of service
sector statistics. Over the past ten years, revisions to services output have accounted
for more than half of the average revision to GDP growth; and around four-fifths of
the variance of GDP revisions can be attributed to revisions to service sector growth.
Indeed, research by Bank staff has indicated that the private-sector business surveys
may give a better guide to the ONS’s estimate of service sector output growth two
years or more after the event than do the ONS’s own early estimates. (In contrast, the
ONS’s early estimates of manufacturing output growth clearly outperform the
business surveys as a guide to later estimates.)
The ONS is well aware of this imbalance. In fact, it has been at the forefront of
developing and improving measures of service sector output: within the OECD only
the UK and Korea produce a monthly Index of Services production, the counterpart to
the well-established monthly Index of Production for the industrial sector. The
Allsopp Report should give further welcome impetus to this work.
The third focus of the Allsopp Report is the capacity of the ONS to identify and
respond to structural change in the economy. The make-up of UK economic activity
is constantly changing. Fifty years ago, the manufacturing industry accounted for
about one-third of UK output. The service sector made up less than one-half. Today,
the corresponding shares are less than 16% for manufacturing, and over 70% for
services.
Responding to this sort of change is challenging. ONS needs to be proactive in
measuring activity in new sectors, even if it is not straightforward – as it often won’t
be. For example, bricks-and-mortar retailing is tangible and growing rapidly, but how
does it compare with developments in internet sales? People can now make some
purchases via mobile phone text message. How can we measure that? Allsopp
recommends a greater capacity within the ONS for considering these issues.

13
Improving the quality of macroeconomic data is a first order issue for monetary
policy makers. So Bank of England staff will play an active role in supporting these
developments.
But it is just as important for the ONS to maintain the quality of its current output
during this period of major transition. Again, we will be working closely with the
ONS to ensure that the transition is made with minimal impact on day-to-day policy.
How well placed are we to respond to more challenging times?
We live in highly uncertain times. This year rising oil prices and a significant
slowdown in the housing market have awoken bad memories of the 1970s and 1980s.
The MPC will be doing very well if it can achieve the same stability over the next
decade as we have enjoyed over the past ten years. But an important legacy of the past
decade is that policy makers enjoy a degree of credibility that would have seemed
unimaginable a generation ago. This in itself reduces the risk that sharp shocks to
activity or inflation will throw us off course.
But there is no magic about monetary policy: good decisions depend on good
information, and this continues to be a challenging area. Much of the MPC’s energies
go into distilling the message from a battery of often conflicting data. We do not
complain about this – it is what we are paid for – but it does complicate the task of
explaining our decisions. Improving the quality of national statistics lacks some of
the glamour of making the Bank of England independent. But it may be the best
single way of ensuring that the MPC continues to respond effectively to challenging
times ahead.

